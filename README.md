# MorVess
<div align="center">
>üìã MorVess: Morphology-Aware Vessel Segmentation Network

# Morphology-Aware Vessel Segmentation Network

<div align="center">

[![Paper](https://img.shields.io/badge/Paper-Media_Image_Analysis-blue)](path/to/paper)
[![Framework](https://img.shields.io/badge/PyTorch-2.0-red)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)](LICENSE)
[![SOTA](https://img.shields.io/badge/SOTA-Parse2022%20%26%20AIIB2023-yellow)]()

<img src="assets/teaser_fig5.png" width="800px" >

**Fuyou Mao**, Yifei Chen*, Beining Wu, Lixin Lin, Jinnan Dai, Zhiling Li, Yilei Chen, Hao Zhang, Yan Tang**, Feiwei Qin**

*Hangzhou Dianzi University | Central South University | Tsinghua University*

</div>

---

## üî• Highlights

> **"Explicit geometric intelligence meets foundation model adaptation."**

* **Morphology-Aware Supervision:** Introduces differentiable **Vessel Distance Map (VDM)** and **Vessel Thickness Map (VTM)** to enforce boundary precision and caliber consistency.
* **Resource-Efficient:** A lightweight **2.5D Adapter** injects 3D context into a frozen SAM encoder.**Only 1.0M trainable parameters** (vs. 32M in nnU-Net).
* **Topological Integrity:** Dynamic **Global-Local Fusion Block (GLFB)** significantly improves small-vessel connectivity.
* **SOTA Performance:** Outperforms nnU-Net, Swin-UNETR, and SegMamba on **Parse2022** and **AIIB2023** benchmark.

---
## üèóÔ∏è Architecture

<div align="center">
  <img src="assets/architecture_fig1.png" width="800">
</div>

[cite_start]MorVess adopts a **Two-Stage Resource-Friendly Training Strategy**[cite: 86]:
1.  **Stage I (Adaptation):** High Learning Rate (HLR) training of the 2.5D Adapter and Decoder heads while keeping SAM frozen.
2.  **Stage II (Refinement):** Low Learning Rate (LLR) fine-tuning for topological perfection.

---

## üìä Results

### Quantitative Comparison (Parse2022)
| Method | Dice (%) | clDice (%) | HD95 (mm) | Param (M) |
| :--- | :---: | :---: | :---: | :---: |
| nnU-Net V2 | 77.28 | 75.31 | 9.53 | 32.0 |
| SegMamba | 79.24 | 73.18 | 9.91 | - |
| COMMA | 83.27 | 80.10 | 5.11 | - |
| **MorVess (Ours)** | **86.84** | **83.22** | **4.53** | **1.0 (Trainable)** |





## üí°Primary contributions

To overcome the challenges of missing or incomplete MRI modalities in brain tumor segmentation, we propose **MST-KDNet**. This is a novel framework for **cross-modality consistency** and **robust tumor segmentation in 3D medical images based on knowledge distillation and style matching**. Our key contributions are summarized as follows:

1) üïê A geometry-prior-driven paradigm for vascular segmentation is proposed, in which the joint supervision of VTM and VDM significantly enhances the model‚Äôs topological and geometric awareness.

2) üïë A lightweight and efficient 2.5D cross-slice attention framework with an FB is designed, substantially improving the continuity and completeness of fine vessels;

3) üïí A low-resource-friendly two-stage training strategy is developed, offering a new perspective for the efficient adaptation of large pre-trained models in 3D medical image segmentation tasks.


## üßóProposed method
<br><br>
![](./img/flowchart.png)
<br><br>

Overview of the MorVess framework. MorVess is a novel geometry-regularized segmentation framework built upon a modified SAM architecture. It comprises three main components: (1) Lightweight \textbf{2.5D Adapters} injected into the frozen ViT encoder to efficiently capture inter-slice spatial context from 2.5D inputs. (2) A multi-head geometric decoder that, within a multi-task learning paradigm, jointly predicts the binary \textbf{Mask} and two continuous, differentiable geometric priors: the \textbf{Vessel Distance Map (VDM)} and the \textbf{Vessel Thickness Map (VTM)}. (3) A \textbf{Global-Local Fusion Block (GLFB)} that aggregates shallow ($F_{sha}$) and deep ($F_{dep}$) encoder features, decoder features ($F_{dec}$), and the self-predicted VDM and VTM to reconstruct high-fidelity vascular details. The framework employs a \textbf{two-stage fine-tuning strategy}: Stage 1 trains the 2.5D Adapters and decoder with a high learning rate (HLR); Stage 2 freezes the adapters and fine-tunes only the decoder and GLFB module with a low learning rate (LLR) to achieve progressive refinement from macro-structure adaptation to micro-topological details.

Core Components:

Vessel Distance Map (VDM): Encodes the distance from each foreground voxel to the nearest vessel wall, forming a smooth boundary potential field.

Vessel Thickness Map (VTM): Provides continuous information about vessel caliber distribution based on the maximum inscribed sphere along the centerline.

Two-Stage Training:

Stage I (HLR): Freezes the SAM encoder; trains the Adapter and Decoder with a high learning rate.

Stage II (LLR): Freezes the Adapter; fine-tunes the Decoder and GLFB with a low learning rate for topological refinement.

## Table of Contents
- [Requirements](#-Requirements)
- [Training](#-Training)
- [Evaluation](#-Evaluation)
- [Results](#-Results)
- [Contributing](#-Contributing)

## üìù Requirements

To install requirements:

```setup
pip install -r requirements.txt
```

üîÑ Data Preparation

Data Structure: Ensure your dataset (Parse2022 or AIIB2023) is organized with raw CT volumes and corresponding segmentation masks.

Preprocessing: Run the preprocessing script to generate 2.5D slices and geometric priors (VDM/VTM).




## üî• Training

To train our model in the paper, run this command:

```train
python train.py
```

>üìã Before training, specify the data set and training configuration using the config.xml file

## üìÉ Evaluation

To evaluate our model in the paper, run this command:

```eval
python eval.py
```

<br><br>
![](./imgs/fig2.png)
<br><br>

>üìã Comparison of segmentation results under four missing-modality scenarios: (1) all modalities, (2) FLAIR + T1ce + T2, (3) FLAIR + T1ce, and (4) FLAIR only. From left to right, the figure shows T1, T2, T1ce, and FLAIR images; ground-truth labels for two patients; three columns of comparison-study results; three columns of ablation-study results; and our final segmentation. Color legend: WT = red + yellow + green, TC = red + yellow, ET = red.
  
## üöÄ Results

Our model achieves the following performance on :

<table style="width:100%; border-collapse: collapse;">
  <thead>
    <tr>
      <th rowspan="2" align="left" style="border: 1px solid #ddd; padding: 8px;"><b>Method</b></th>
      <th colspan="6" align="center" style="border: 1px solid #ddd; padding: 8px;"><b>Parse2022 Dataset (98 cases)</b></th>
      <th colspan="6" align="center" style="border: 1px solid #ddd; padding: 8px;"><b>AIIB2023 Dataset (120 cases)</b></th>
      <th rowspan="2" align="center" style="border: 1px solid #ddd; padding: 8px;"><b>Code Avail</b></th>
    </tr>
    <tr>
      <th align="center" style="border: 1px solid #ddd; padding: 8px;">Dice‚Üë</th>
      <th align="center" style="border: 1px solid #ddd; padding: 8px;">Cldice‚Üë</th>
      <th align="center" style="border: 1px solid #ddd; padding: 8px;">HD<sub>95</sub>(mm)‚Üì</th>
      <th align="center" style="border: 1px solid #ddd; padding: 8px;">AMR‚Üì</th>
      <th align="center" style="border: 1px solid #ddd; padding: 8px;">DBR‚Üë</th>
      <th align="center" style="border: 1px solid #ddd; padding: 8px;">DLR‚Üë</th>
      <th align="center" style="border: 1px solid #ddd; padding: 8px;">Dice‚Üë</th>
      <th align="center" style="border: 1px solid #ddd; padding: 8px;">Cldice‚Üë</th>
      <th align="center" style="border: 1px solid #ddd; padding: 8px;">HD<sub>95</sub>(mm)‚Üì</th>
      <th align="center" style="border: 1px solid #ddd; padding: 8px;">AMR‚Üì</th>
      <th align="center" style="border: 1px solid #ddd; padding: 8px;">DBR‚Üë</th>
      <th align="center" style="border: 1px solid #ddd; padding: 8px;">DLR‚Üë</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align="left" style="border: 1px solid #ddd; padding: 8px;">VISTA3d</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">67.24</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">63.21</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">14.23</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.33</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.55</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.68</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">83.81</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">76.24</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">9.23</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.25</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.58</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.67</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><a href="https://github.com/Project-MONAI/VISTA">Code</a></td>
    </tr>
    <tr>
      <td align="left" style="border: 1px solid #ddd; padding: 8px;">nnunet-v2</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">77.28</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">75.31</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">9.53</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.22</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.66</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.72</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">92.83</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">84.31</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">5.92</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.10</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.77</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.83</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><a href="https://github.com/your/repo/url">Code</a></td>
    </tr>
    <tr>
      <td align="left" style="border: 1px solid #ddd; padding: 8px;">Swin-unetr</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">76.85</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">70.19</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">11.26</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.28</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.61</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.75</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">90.53</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">80.13</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">8.42</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.19</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.74</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.78</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><a href="https://github.com/your/repo/url">Code</a></td>
    </tr>
    <tr>
      <td align="left" style="border: 1px solid #ddd; padding: 8px;">Segmamba</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">79.24</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">73.18</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">9.91</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.25</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.65</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.74</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">91.29</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">85.51</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">4.59</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.12</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.68</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.79</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><a href="https://github.com/your/repo/url">Code</a></td>
    </tr>
    <tr>
      <td align="left" style="border: 1px solid #ddd; padding: 8px;">Diff-UNet</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">76.24</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">71.26</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">9.65</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.27</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.62</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.68</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">90.48</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">86.32</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">4.67</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.11</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.64</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.76</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><a href="https://github.com/your/repo/url">Code</a></td>
    </tr>
    <tr>
      <td align="left" style="border: 1px solid #ddd; padding: 8px;">dscNet</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">80.32</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">81.03</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">5.35</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.16</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.73</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.78</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">92.15</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">85.22</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">5.39</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.10</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.80</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.81</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><a href="https://github.com/your/repo/url">Code</a></td>
    </tr>
    <tr>
      <td align="left" style="border: 1px solid #ddd; padding: 8px;">COMMA</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">83.27</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">80.10</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">5.11</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.14</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.75</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.79</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">92.88</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">86.23</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">4.25</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.09</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.81</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;">0.84</td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><a href="https://github.com/your/repo/url">Code</a></td>
    </tr>
    <tr>
      <td align="left" style="border: 1px solid #ddd; padding: 8px;"><b>MorVess(Ours)</b></td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><b>86.84</b></td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><b>83.22</b></td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><b>4.53</b></td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><b>0.12</b></td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><b>0.80</b></td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><b>0.83</b></td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><b>94.31</b></td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><b>89.34</b></td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><b>3.24</b></td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><b>0.07</b></td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><b>0.86</b></td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><b>0.89</b></td>
      <td align="center" style="border: 1px solid #ddd; padding: 8px;"><a href="https://github.com/MaoFuyou/MorVess.git">Code</a></td>
    </tr>
  </tbody>
</table>
**2. Bimodal & Trimodal Gains**

Adding a second or third modality further reduces boundary error and boosts accuracy. This improvement is driven by the **Global Style Matching Module (GSME)**, which adversarially aligns global feature statistics‚Äîmean and variance‚Äîbetween the student‚Äôs fused features and the teacher‚Äôs multi‚Äëmodal style. By correcting modality‚Äëspecific brightness and texture shifts, GSME ensures that the student sees a consistent ‚Äúappearance‚Äù regardless of which sequences are present, sharpening tumor boundaries and reducing spurious errors.

* **Bimodal inputs** (e.g. T1Gd‚ÄØ+‚ÄØT2, T1‚ÄØ+‚ÄØT1Gd, ‚Ä¶)

  * Dice **79.8‚ÄØ%‚Äì85.7‚ÄØ%‚ÄØ/‚ÄØ50.1‚ÄØ%‚Äì71.3‚ÄØ%‚ÄØ/‚ÄØ48.5‚ÄØ%‚Äì72.3‚ÄØ%**, outperforming competitors by 3‚Äì8‚ÄØpp
  * HD95 **4.6‚ÄØmm‚Äì9.2‚ÄØmm‚ÄØ/‚ÄØ3.7‚ÄØmm‚Äì10.5‚ÄØmm‚ÄØ/‚ÄØ3.3‚ÄØmm‚Äì10.6‚ÄØmm** vs. SMUNet‚Äôs **5.1‚ÄØmm‚Äì11.2‚ÄØmm‚ÄØ/‚ÄØ4.2‚ÄØmm‚Äì12.2‚ÄØmm‚ÄØ/‚ÄØ2.8‚ÄØmm‚Äì12.0‚ÄØmm**

* **Trimodal inputs** (e.g. FLAIR‚ÄØ+‚ÄØT1‚ÄØ+‚ÄØT1Gd, ‚Ä¶)

  * Dice **80.0‚ÄØ%‚Äì86.9‚ÄØ%‚ÄØ/‚ÄØ59.5‚ÄØ%‚Äì73.1‚ÄØ%‚ÄØ/‚ÄØ59.8‚ÄØ%‚Äì73.9‚ÄØ%**, again leading by several points
  * HD95 **4.7‚ÄØmm‚Äì5.1‚ÄØmm‚ÄØ/‚ÄØ3.4‚ÄØmm‚Äì5.1‚ÄØmm‚ÄØ/‚ÄØ2.9‚ÄØmm‚Äì5.3‚ÄØmm** vs. SMUNet‚Äôs **4.8‚ÄØmm‚Äì5.3‚ÄØmm‚ÄØ/‚ÄØ3.7‚ÄØmm‚Äì4.3‚ÄØmm‚ÄØ/‚ÄØ2.8‚ÄØmm‚Äì5.3‚ÄØmm**

Here, GSME‚Äôs style alignment translates directly into crisper edges (lower HD95) and higher overlap (Dice) when combining modalities.

**3. Full‚ÄëModality Peak Performance**

With all four modalities available, MST‚ÄëKDNet maximizes both accuracy and boundary fidelity through **Dual‚ÄëMode Logit Distillation (DMLD)**. DMLD employs a combined mean‚Äêsquared error on logits and a temperature‚Äëscaled KL divergence to smooth out discrepancies between the student‚Äôs outputs under missing‚Äëmodality and full‚Äëmodality conditions. This dual‚Äëmode supervision ensures predictions remain stable and consistent, ironing out boundary irregularities and false positives.

* **Dice (WT/TC/ET):** **86.8‚ÄØ%‚ÄØ/‚ÄØ73.1‚ÄØ%‚ÄØ/‚ÄØ73.9‚ÄØ%** vs. SMUNet‚Äôs 79.7‚ÄØ%‚ÄØ/‚ÄØ50.7‚ÄØ%‚ÄØ/‚ÄØ49.3‚ÄØ%
* **HD95 (WT/TC/ET):** **6.6‚ÄØmm‚ÄØ/‚ÄØ7.2‚ÄØmm‚ÄØ/‚ÄØ6.8‚ÄØmm** vs. SMUNet‚Äôs 7.4‚ÄØmm‚ÄØ/‚ÄØ8.5‚ÄØmm‚ÄØ/‚ÄØ8.0‚ÄØmm

DMLD‚Äôs logit‚Äëlevel alignment is the final refinement that pushes both Dice and HD95 to their optimal values under ideal input.


### [Comparison Experiment on BraTS 2024 with Dice metric](https://www.synapse.org/Synapse:syn53708249)

| Type   | Model      | T2   | T1Gd | T1   | FLAIR | T1Gd+T2 | T1+T1Gd | FLAIR+T1 | T1+T2 | FLAIR+T2 | FLAIR+T1Gd | FLAIR+T1+T1Gd | FLAIR+T1+T2 | FLAIR+T1Gd+T2 | T1+T1Gd+T2 | FLAIR+T1+T1Gd+T2 | Avg.  |
| :----: | :--------: | :----: | :-----: | :-----: | :------: | :-------: | :-------: | :--------: | :-----: | :--------: | :-----------: | :--------------: | :-----------: | :--------------: | :-----------: | :----------------: | :-----: |
| **WT** | RA-HVED    |   75.4  |   51.3  |    9.5  |    71.4  |      77.5  |      53.4  |      72.9   |   76.1   |      80.1   |      72.9     |         80.6     |     80.4     |         77.7     |     80.1    |             68.8    |  68.8 |
|        | RMBTS      |   70.1  |   51.2  |   51.8  |    65.0  |      75.3  |      60.6  |      76.4   |   75.0   |      77.3   |      76.0     |         79.7     |     80.3     |         76.1     |     80.9    |             71.7    |  71.7 |
|        | mmformer   |   72.6  |   55.5  |   61.3  |    72.7  |      74.3  |      65.4  |      79.2   |   75.1   |      79.6   |      78.3     |         80.7     |     81.0     |         75.6     |     81.3    |             74.2    |  74.2 |
|        | M2FTrans   |   72.5  |   58.8  |   62.0  |    73.0  |      73.9  |      64.2  |      77.4   |   73.6   |      78.9   |      77.0     |         78.5     |     79.5     |         74.2     |     78.8    |             73.3    |  73.3 |
|        | ACN        |   69.6  |   58.7  |   60.1  |    80.7  |      71.8  |      63.6  |      82.1   |   72.2   |      82.3   |      81.3     |         82.8     |     82.0     |         72.5     |     82.5    |             75.0    |  75.0 |
|        | SMUNet     |   75.0  |   67.9  |   69.6  |    84.2  |      76.7  |      70.6  |      84.6   |   77.1   |      85.2   |      85.2     |         85.6     |     86.0     |         77.2     |     86.0    |             79.7    |  79.7 |
|        | MST‚ÄëKDNet  |**77.2** |**72.9** |**73.5** |**84.7**  |**79.8**    |**75.1**    |**85.7**     |**79.3**  |**85.8**     |**86.4**        |**86.5**           |**86.1**       |**86.9**           |**80.0**      |**86.8**             |**81.8**|
| **TC** | RA-HVED    |   26.5  |   54.2  |    9.4  |**41.1**  |      61.3  |      54.8  |      41.9   |   29.2   |      40.5   |      61.9     |         62.5     |     43.2     |         64.0     |     61.9    |             65.0    |  47.8 |
|        | RMBTS      |   10.9  |   36.5  |   12.6  |    11.2  |      40.4  |      37.6  |      16.8   |   15.2   |      14.5   |      38.9     |         40.1     |     17.4     |         40.4     |     40.9    |             40.6    |  27.6 |
|        | mmformer   |   47.2  |   52.3  |   44.4  |    33.1  |      62.6  |      60.6  |      49.6   |**51.1**  |      49.6   |      60.6     |         64.3     |     52.6     |         65.5     |     65.3    |             67.0    |  55.1 |
|        | M2FTrans   |   46.6  |   53.3  |   43.3  |    33.8  |      60.0  |      57.7  |      46.7   |   48.5   |      48.3   |      57.8     |         60.0     |     49.6     |         61.5     |     60.8    |             62.0    |  52.7 |
|        | ACN        |   21.2  |   54.2  |   19.5  |    22.5  |      58.8  |      57.9  |      26.1   |   23.2   |      26.7   |      60.0     |         63.8     |     28.3     |         62.6     |     62.7    |             64.1    |  43.4 |
|        | SMUNet     |   29.3  |   64.1  |   28.2  |    28.8  |      67.3  |      67.1  |      32.6   |   31.5   |      32.5   |      66.9     |         70.4     |     33.7     |         69.4     |     69.1    |             69.8    |  50.7 |
|        | MST‚ÄëKDNet  |**47.3** |**68.3** |**44.5** |    33.9  |**70.3**    |**71.3**    |**50.1**     |   41.5   |**50.2**     |**72.0**       |**74.1**           |**53.6**       |**72.5**          |**72.6**     |**73.1**            |**59.5**|
| **ET** | RA-HVED    |   35.8  |   37.8  |    9.2  |    39.8  |      42.3  |      36.6  |      42.6   |   43.8   |      44.4   |      44.1     |         43.9     |     48.4     |         46.8     |     40.7    |             45.9    |  40.1 |
|        | RMBTS      |    7.9  |   37.8  |   10.0  |     8.2  |      41.9  |      40.1  |      13.1   |   11.8   |      10.8   |      40.6     |         43.5     |     14.0     |         42.3     |     44.1    |             55.2    |  28.1 |
|        | mmformer   |   44.9  |   50.5  |   42.3  |    31.4  |      61.3  |      59.0  |      45.3   |   49.4   |      46.6   |      59.3     |         63.0     |     49.6     |         63.6     |     64.2    |             65.7    |  53.1 |
|        | M2FTrans   |   47.1  |   54.2  |**44.6** |    34.0  |      62.6  |      60.0  |      47.5   |   49.4   |      49.3   |      60.2     |         62.7     |     50.4     |         64.5     |     63.4    |             65.0    |  54.3 |
|        | ACN        |   18.0  |   55.2  |   16.9  |    19.6  |      59.8  |      59.6  |      22.2   |   19.2   |      22.4   |      60.8     |         65.1     |     23.9     |         64.0     |     64.3    |             65.9    |  42.5 |
|        | SMUNet     |   25.5  |   64.8  |   25.0  |    25.1  |      67.9  |      68.1  |      28.6   |   27.6   |      28.6   |      67.9     |         70.6     |     29.7     |         69.8     |     70.1    |             70.8    |  49.3 |
|        | MST‚ÄëKDNet  |**48.3** |**68.6** |   32.0  |**40.6**  |**70.0**    |**72.3**    |**48.5**     |**50.1**  |**51.1**     |**72.4**       |**74.9**           |**52.5**       |**72.8**          |**73.1**     |**73.9**            |**59.8**|

### [Comparison Experiment on BraTS 2024 with HD95 metric](https://www.synapse.org/Synapse:syn53708249)

|   Type   |    Model     |  T2  | T1Gd |  T1  | FLAIR | T1Gd+T2 | T1+T1Gd | FLAIR+T1 | T1+T2 | FLAIR+T2 | FLAIR+T1Gd | FLAIR+T1+T1Gd | FLAIR+T1+T2 | FLAIR+T1Gd+T2 | T1+T1Gd+T2 | FLAIR+T1+T1Gd+T2 |  Avg.   |
|:--------:|:------------:|:------:|:------:|:------:|:-------:|:---------:|:---------:|:----------:|:-------:|:----------:|:------------:|:---------------:|:------------:|:---------------:|:-----------:|:-----------------:|:-------:|
| **WT**   | RA‚ÄëHVED      | 22.1   | 40.2   | 57.7   | 23.8    | 19.8      | 34.8      | 20.9       | 17.4    | 16.9       | 21.2         | 20.5            | 15.0         | 16.3            | 18.6         | 15.9              | 24.1    |
|          | RMBTS        | 39.1   | 63.6   | 57.7   | 59.4    | 36.1      | 50.1      | 41.7       | 33.1    | 37.4       | 47.8         | 34.8            | 33.2         | 35.3            | 34.1         | 34.0              | 42.5    |
|          | mmformer     | 19.5   | 52.0   | 40.7   | 18.2    | 18.8      | 34.5      | 13.9       | 16.8    | 13.1       | 15.5         | 13.4            | 12.9         | 12.2            | 16.8         | 11.8              | 20.7    |
|          | M2FTrans     | 43.8   | 51.8   | 47.0   | 47.3    | 42.4      | 44.5      | 43.0       | 42.6    | 42.1       | 41.9         | 41.3            | 41.3         | 40.7            | 40.8         | 40.5              | 43.4    |
|          | ACN          | 11.6   | 28.4   | 29.6   | 11.8    | 13.5      | 20.4      | 11.4       | 15.6    | 10.3       | 13.2         | 11.7            | 10.2         | 11.5            | 15.1         | 10.3              | 15.0    |
|          | SMUNet       |  9.1   | 13.3   |**5.9** | 12.2    |  5.9      |**7.6**    | 11.2       |  5.4    |  7.7       |**5.1**       |  5.2            |  5.3         |  4.9            |  4.8         |  8.0              |  7.4    |
|          | MST‚ÄëKDNet    |**8.1** |**11.1**| 11.0   |**6.7**  |**5.3**    |  9.2      |**6.1**     |**5.2**  |**4.6**     |  6.2         |**5.1**          |**5.0**       |**4.7**          |**4.7**       |**5.3**            |**6.6**  |
| **TC**   | RA-HVED      | 25.3   | 30.4   | 57.1   | 22.5    | 15.8      | 26.8      | 20.9       | 23.1    | 19.7       | 15.9         | 14.4            | 21.6         | 13.3            | 16.2         | 12.5              | 22.4    |
|          | RMBTS        | 24.8   | 23.1   | 47.1   | 24.1    | 19.8      | 25.8      | 23.7       | 21.9    | 19.1       | 18.5         | 16.3            | 20.0         | 15.6            | 14.0         | 13.7              | 21.8    |
|          | mmformer     | 27.7   | 62.1   | 39.1   | 24.3    | 25.6      | 38.7      | 19.7       | 24.1    | 19.3       | 20.5         | 17.3            | 18.7         | 15.4            | 22.1         | 14.7              | 26.0    |
|          | M2FTrans     | 79.4   | 79.2   | 82.6   | 82.4    | 76.3      | 76.3      | 79.7       | 79.2    | 79.5       | 78.5         | 77.5            | 78.3         | 77.0            | 77.0         | 76.3              | 78.6    |
|          | ACN          | 15.7   |  9.2   | 19.3   | 18.2    |  6.4      |  8.5      | 17.3       | 17.0    | 15.7       |  6.6         |  6.2            | 17.6         |  5.8            |  6.2         |  5.8              | 11.7    |
|          | SMUNet       | 14.0   |  6.3   | 14.0   | 13.4    |  4.4      |  5.0      | 12.2       | 12.1    | 12.0       |  4.8         |  4.3            | 11.9         |  4.2            |  4.5         |  4.6              |  8.5    |
|          | MST‚ÄëKDNet    |**12.0**|**4.9** |**11.2**|**12.1** |**3.7**    |**4.3**    |**10.5**    |**10.8** |**11.0**    |**3.6**       |**3.4**          |**10.0**      |**3.7**          |**3.3**       |**4.0**            |**7.2**  |
| **ET**   | RA-HVED      | 12.9   | 25.0   | 47.0   | 15.2    | 14.9      | 23.7      | 13.2       | 10.9    | 10.8       | 14.0         | 14.2            | 11.0         | 12.8            | 15.4         | 12.2              | 16.9    |
|          | RMBTS        | 23.8   | 21.9   | 44.8   | 23.7    | 19.2      | 24.2      | 22.4       | 21.9    | 19.5       | 17.2         | 15.1            | 19.5         | 15.2            | 13.5         | 13.3              | 21.0    |
|          | mmformer     | 26.4   | 59.8   | 37.6   | 23.2    | 24.0      | 36.7      | 18.6       | 22.2    | 18.4       | 18.3         | 16.4            | 17.7         | 14.5            | 20.4         | 14.0              | 24.5    |
|          | M2FTrans     | 23.4   | 31.5   | 21.5   | 24.1    | 16.1      | 16.2      | 16.2       | 19.4    | 20.9       | 16.8         | 13.3            | 18.5         | 15.3            | 14.2         | 13.9              | 18.8    |
|          | ACN          | 14.7   |  8.0   | 19.3   | 18.1    |  6.1      |  7.6      | 16.6       | 16.4    | 14.9       |  5.9         |  5.3            | 17.2         |  5.2            |  5.3         |  5.2              | 11.1    |
|          | SMUNet       | 13.5   |  5.4   | 14.0   | 13.0    |  3.9      |  4.3      | 11.8       | 11.5    | 12.0       |  4.1         |  3.7            | 11.3         |  3.7            |  4.0         |  4.0              |  8.0    |
|          | MST‚ÄëKDNet    |**11.7**|**4.5** |**10.5**|**11.9** |**3.3**    |**3.8**    |**9.8**     |**10.3** |**10.6**    |**3.2**       |**3.0**          |**9.8**       |**3.3**          |**2.9**       |**3.0**            |**6.8**  |

---

### Comparative Experiments on BraTS‚ÄØ2024

**1. Unimodal Robustness**  
Even with only a single MRI sequence, MST‚ÄëKDNet keeps boundaries tight thanks to **Multi‚ÄëScale Transformer Knowledge Distillation (MS‚ÄëTKD)**. By transferring the teacher‚Äôs multi‚Äëresolution attention ‚Äúhints,‚Äù the student retrieves global tumor context from just one input.

- **T2 only:** HD95 drops to ~6.5‚ÄØmm (vs. ~7.1‚ÄØmm in other methods)  
- **T1Gd only:** HD95 around ~9.4‚ÄØmm (vs. ~10.1‚ÄØmm)  
- **T1 only:** HD95 near ~10.2‚ÄØmm (vs. ~11.2‚ÄØmm)  
- **FLAIR only:** HD95 shrinks to ~5.0‚ÄØmm (vs. ~5.9‚ÄØmm)

MS‚ÄëTKD‚Äôs distilled attention makes up for missing modalities, preserving both shape and location fidelity.


**2. Bimodal & Trimodal Gains**  
Adding a second or third sequence further refines edges through the **Global Style Matching Module (GSME)**, which standardizes feature ‚Äústyle‚Äù across modalities.

- **Bimodal inputs:** average HD95 falls by 1‚Äì2‚ÄØmm compared to two‚Äësequence baselines  
- **Trimodal inputs:** boundaries tighten further to ~4‚Äì5‚ÄØmm HD95

GSME‚Äôs adversarial style alignment corrects contrast and texture shifts, yielding consistently crisper tumor margins.


**3. Full‚ÄëModality Peak Performance**  
With all four sequences, **Dual‚ÄëMode Logit Distillation (DMLD)** polishes the final output by aligning logits from missing‚Äë and full‚Äëmodality paths.

- **All four modalities:** HD95 reaches ~4.1‚ÄØmm‚Äîthe lowest across all configurations

DMLD‚Äôs combined MSE and KL losses smooth out residual inconsistencies, ensuring the sharpest, most reliable boundaries when data is complete.

### [Comparison Experiment on FeTS 2024 with Dice metric](https://www.synapse.org/Synapse:syn53708249)

|   Type   |    Model     |   T2   |  T1Gd  |   T1   |  FLAIR  | T1Gd+T2 | T1+T1Gd | FLAIR+T1 | T1+T2 | FLAIR+T2 | FLAIR+T1Gd | FLAIR+T1+T1Gd | FLAIR+T1+T2 | FLAIR+T1Gd+T2 | T1+T1Gd+T2 | FLAIR+T1+T1Gd+T2 |  Avg  |
|:--------:|:------------:|:------:|:------:|:------:|:-------:|:-------:|:-------:|:--------:|:-----:|:--------:|:----------:|:-------------:|:-----------:|:-------------:|:----------:|:----------------:|:-----:|
| **WT**   | RA‚ÄëHVED      |  71.1  |  54.4  |  49.6  |  66.4   |  75.3   |  59.7   |   66.6   |  75.7 |   75.1   |    69.2    |      70.3      |    79.1     |      77.2     |    76.2    |       80.0       |  69.7 |
|          | RMBTS        |  69.9  |  54.6  |  65.6  |  71.8   |  71.5   |  70.0   |   83.3   |  80.1 |   76.2   |    73.4    |      84.0      |    84.8     |      76.5     |    80.8    |       85.2       |  75.2 |
|          | mmformer     |  66.2  |  59.9  |  50.6  |  70.8   |  68.8   |  62.7   |   72.8   |  67.5 |   73.7   |    73.8    |      74.1      |    73.6     |      74.5     |    69.7    |       74.3       |  68.9 |
|          | M2FTrans     |  81.9  |  71.0  |  65.9  |  79.4   |  84.4   |  75.6   |   84.6   |  83.8 |   86.7   |    84.2    |      85.8      |    87.2     |      87.7     |    84.8    |       87.8       |  82.0 |
|          | ACN          |  84.0  |  74.2  |  71.3  |  88.4   |  85.6   |  75.9   |   88.6   |  85.6 |   89.2   |    88.6    |      88.9      |    89.1     |      89.5     |    85.7    |       89.6       |  84.9 |
|          | SMUNet       |  86.7  |  78.8  |  77.4  |  90.0   |  87.8   |  80.6   |   90.6   |  87.7 |   90.7   |    90.5    |      90.7      |    91.0     |      91.2     |    88.0    |       91.4       |  87.5 |
|          | MST‚ÄëKDNet    |**87.6**|**81.4**|**80.3**|**90.3** |**88.2** |**82.8** |**90.9**  |**88.4**|**91.2**  |**91.1**    |**91.2**        |**91.3**     |**91.5**       |**88.4**   |**91.5**         |**88.4**|
| **TC**   | RA‚ÄëHVED      |  47.1  |  63.8  |  35.0  |  45.3   |  70.1   |  69.1   |   45.2   |  51.5 |   50.5   |    71.8    |      71.2      |    52.4     |      74.5     |    75.5    |       77.9       |  60.0 |
|          | RMBTS        |  46.4  |  39.2  |  69.9  |  40.6   |  50.6   |  71.2   |   71.9   |  72.3 |   52.2   |    48.1    |      72.2      |    72.5     |      53.5     |    72.5    |       72.8       |  60.4 |
|          | mmformer     |  42.0  |  59.5  |  32.9  |  42.2   |  64.7   |  64.0   |   47.7   |  44.0 |   47.9   |    62.5    |      65.8      |    49.3     |      64.1     |    65.9    |       66.0       |  54.6 |
|          | M2FTrans     |  57.6  |  81.2  |  52.9  |  59.7   |  85.3   |  81.2   |   66.9   |  62.4 |   67.6   |    84.6    |      85.3      |    69.4     |      86.0     |    85.9    |       85.6       |  74.3 |
|          | ACN          |  67.9  |  85.6  |  59.9  |  69.6   |  87.7   |  86.8   |   70.9   |  68.6 |   71.5   |    87.9    |      88.6      |    71.7     |      87.7     |    88.5    |       88.7       |  78.8 |
|          | SMUNet       |  74.2  |  88.6  |  70.4  |  74.5   |  90.0   |  89.2   |   76.1   |  74.9 |   76.4   |    90.4    |      90.5      |    76.9     |      90.6     |    90.2    |       90.6       |  82.9 |
|          | MST‚ÄëKDNet    |**76.2**|**90.0**|**73.0**|**76.9** |**90.9** |**90.7** |**78.5**  |**76.5**|**78.8**  |**90.8**    |**91.1**        |**78.5**     |**91.0**       |**90.9**   |**91.1**         |**84.3**|
| **ET**   | RA‚ÄëHVED      |  32.2  |  61.1  |  22.3  |  28.5   |  67.6   |  66.2   |   29.3   |  32.9 |   34.5   |    67.4    |      66.5      |    36.4     |      71.3     |    72.7    |       74.0       |  50.9 |
|          | RMBTS        |  45.3  |  38.0  |**78.7**|  39.9   |  49.3   |  81.3   |**83.0**  |**82.5**|   51.2   |    47.7    |  83.4          |**83.4**     |      53.1     |   83.6 |      83.8    |  65.6 |
|          | mmformer     |  25.4  |  60.2  |  12.5  |  31.9   |  61.7   |  64.4   |   33.8   |  25.8 |   35.1   |    62.0    |      64.4      |    34.9     |      60.9     |    63.3    |       62.6       |  46.6 |
|          | M2FTrans     |  38.4  |  77.6  |  30.7  |  41.4   |  80.5   |  79.6   |   46.1   |  42.6 |   50.1   |    81.2    |      81.5      |    51.5     |      61.2     |    81.0    |       81.1       |  63.0 |
|          | ACN          |  50.3  |  79.7  |  41.5  |  50.8   |  81.9   |  81.3   |   51.7   |  50.7 |   54.3   |    82.5    |      83.0      |    54.3     |      84.7     |    82.2    |       82.6       |  67.3 |
|          | SMUNet       |  57.2  |  83.3  |  52.0  |  56.5   |  84.4   |  84.1   |   58.7   |  58.1 |  60.9    |  85.2      |  85.3          |   61.2     |  84.9         |  84.6     |         84.9      |  72.1 |
|          | MST‚ÄëKDNet    |**59.3**|**84.5**|  54.6  |**59.2** |**85.1** |**84.8** |   61.2   |  59.9  |**62.9**  |**85.6**    |**85.7**        |  62.7     |**85.4**       |**85.3**   |       **85.5**    |**73.4**|

### [Comparison Experiment on FeTS 2024 with HD95 metric](https://www.synapse.org/Synapse:syn53708249)

|   Type   |    Model     |   T2   |  T1Gd  |   T1   |  FLAIR  | T1Gd+T2 | T1+T1Gd | FLAIR+T1 | T1+T2 | FLAIR+T2 | FLAIR+T1Gd | FLAIR+T1+T1Gd | FLAIR+T1+T2 | FLAIR+T1Gd+T2 | T1+T1Gd+T2 | FLAIR+T1+T1Gd+T2 |  Avg  |
|:--------:|:------------:|:------:|:------:|:------:|:-------:|:-------:|:-------:|:--------:|:-----:|:--------:|:----------:|:-------------:|:-----------:|:-------------:|:----------:|:----------------:|:-----:|
| **WT**   | RA‚ÄëHVED      |  23.2  |  31.7  |  36.5  |  27.9   |  18.4   |  25.2   |  25.2    | 21.3  |  21.5    |    20.2    |      17.9      |    16.6     |      16.0     |    14.3     |       13.4        | 22.0  |
|          | RMBTS        |  10.8  |  13.8  |  14.1  |   9.5   |   9.0   |  12.0   |   5.8    |  7.3  |   8.1    |     8.0    |       5.1      |     5.0     |       7.9     |     7.6     |        4.7        |  8.6  |
|          | mmformer     |  26.9  |  34.7  |  31.8  |  33.5   |  28.4   |  28.7   |  25.2    | 24.3  |  24.9    |    24.5    |      22.8      |    23.6     |      23.3     |    26.3     |       21.5        | 26.7  |
|          | M2FTrans     |  35.1  |  32.6  |  29.2  |  26.8   |  25.7   |  27.6   |  24.4    | 28.2  |  23.2    |    27.6    |      24.9      |    22.3     |      23.4     |    23.7     |       23.1        | 26.5  |
|          | ACN          |   9.1  |  13.6  |  16.8  |   6.9   |   7.3   |  12.2   |   7.3    |  7.7  |   6.7    |     7.2    |       7.1      |     6.6     |       6.3     |     7.4     |        5.9        |  8.5  |
|          | SMUNet       |   7.1  |  10.1  |  11.2  |   5.9   | **5.8** |   9.4   |   5.3    |  6.2  |   5.3    |     5.1    |       5.2      |   **4.8**   |      **4.3**  |     5.6     |        4.8        |  6.4  |
|          | MST‚ÄëKDNet    |**6.5** |**9.4** |**10.2**|**5.0**  |   6.1   |**9.0**  | **4.8**  |**5.7**| **5.0**  |  **4.3**   |   **4.3**     |  **4.6**    |   **4.0**    |   **5.8**   |   **4.1**        | **5.9** |
| **TC**   | RA‚ÄëHVED      | 23.3   | 23.6   | 40.2   | 27.8    | 14.7    | 19.1    | 28.1     | 23.5  | 24.5     | 13.4       | 13.8           | 23.2        | 12.7          | 10.0        | 10.6             | 22.4  |
|          | RMBTS        | 33.0   | 35.1   | 22.5   | 30.0    | 32.1    | 19.1    | 19.5     | 19.2  | 29.2     | 27.1       | 20.7           | 21.9        | 27.1          | 20.8        | 20.5             | 25.2  |
|          | mmformer     | 32.9   | 35.2   | 35.7   | 41.7    | 26.9    | 24.3    | 27.7     | 28.7  | 30.4     | 22.3       | 18.4           | 26.4        | 20.7          | 23.6        | 18.3             | 27.5  |
|          | M2FTrans     | 23.5   | 17.1   | 28.5   | 24.4    |  9.4    | 11.6    | 18.7     | 16.3  | 14.1     | 11.6       | 10.2           | 12.9        |  8.2          |  7.0        |  8.4             | 14.8  |
|          | ACN          | 12.7   |  7.3   | 16.8   | 10.7    |  5.0    |  6.2    | 10.4     | 11.6  | 10.9     |  5.3       |  4.8           | 10.7        |  5.0          |  4.7        |  4.4             |  8.4  |
|          | SMUNet       |  9.4   |  5.1   | 11.1   |  8.8    |  3.9    |  4.0    |  8.4     |  8.8  |  8.0     |  3.8       |  3.8           |  8.0        |  3.6          |  3.7        |  3.6             |  6.3  |
|          | MST‚ÄëKDNet    |**9.2** |**3.8** |**10.4**|**8.1**  |**3.3**  |**3.6**  | **7.7**  |**8.6**| **7.3**  | **3.4**    | **3.3**        | **7.6**     | **3.2**        | **3.4**      | **3.2**          | **5.7** |
| **ET**   | RA‚ÄëHVED      | 22.2   | 22.0   | 39.7   | 27.6    | 13.7    | 17.7    | 28.0     | 23.6  | 23.5     | 12.3       | 12.7           | 23.5        | 11.2          |  9.3        |  9.9             | 19.8  |
|          | RMBTS        | 29.0   | 34.2   | 20.9   | 22.1    | 24.7    | 17.0    | 11.8     | 12.3  | 20.3     | 23.8       | 12.4           | 12.7        | 22.2          | 11.3        | 12.4             | 19.1  |
|          | mmformer     | 40.1   | 38.3   | 39.8   | 48.8    | 33.0    | 29.6    | 34.6     | 36.1  | 38.4     | 28.0       | 24.9           | 34.3        | 27.7          | 30.6        | 25.5             | 34.0  |
|          | M2FTrans     | 31.9   | 21.3   | 34.6   | 27.1    | 16.4    | 18.7    | 24.0     | 24.0  | 21.5     | 14.0       | 13.7           | 20.4        | 15.0          | 14.7        | 14.5             | 20.8  |
|          | ACN          | 20.9   | 14.9   | 24.2   | 19.0    | 12.8    | 13.9    | 18.7     | 19.7  | 19.1     | 12.8       | 12.7           | 18.8        | 12.9          | 14.0        | 12.6             | 16.5  |
|          | SMUNet       |**8.8** |  4.0   | 10.3   |  8.3    |  3.0    |  3.1    |  8.1     |**8.6**| **7.4**  |  2.9       |  3.0           | **7.3**     |  2.8          |  2.8        |  2.8             |  5.5  |
|          | MST‚ÄëKDNet    |  9.4   |**2.9** | **9.5**| **8.2** |**2.5**  |**2.8**  | **7.9**  |**8.6**|  7.7     | **2.8**    | **2.7**        |  7.8        | **2.6**        | **2.5**      | **2.6**          | **5.4** |

---

### Ablation Study on BraTS‚ÄØ2024

In the *BraTS‚ÄØ2024* multi‚Äëmodal ablation study, every core module proved critical to safeguarding segmentation performance when one or more modalities were absent:

* **Multi‚ÄëScale Transformer Knowledge Distillation (MS‚ÄëTKD).**  
  By aligning feature maps at multiple resolutions, MS‚ÄëTKD markedly improves the fusion of fine details with broader context. Removing this module reduced the mean **Whole Tumour (WT) Dice** by **2.0‚ÄØpp** and increased **HD95** by **0.9‚ÄØmm**, underscoring its ability to capture rich semantics in missing‚Äëmodality settings.  

* **Dual‚ÄëModality Logit Distillation (DMLD).**  
  Joint optimisation with MSE and normalised KL losses enforces semantic consistency between teacher and student networks. Without DMLD, **Tumour Core (TC) Dice** fell by **3.4‚ÄØpp** and **Enhancing Tumour (ET) Dice** by **4.6‚ÄØpp**, highlighting the necessity of logit alignment for precise delineation under single‚Äë or dual‚Äëmodality input.  

* **Global Style Matching &‚ÄØEnhancement (GSME).**  
  GSME compensates for texture and style discrepancies across modalities. Omitting it cut **ET Dice** by **6.4‚ÄØpp** and raised **HD95** by ‚âà‚ÄØ**2‚ÄØmm**, revealing its key role in boundary fidelity and spatial coherence.

| Method        | WT Dice (%) | Œî      | TC Dice (%) | Œî      | ET Dice (%) | Œî      | WT HD95 (mm) | Œî      | TC HD95 (mm) | Œî      | ET HD95 (mm) | Œî      |
|:-------------:|:-----------:|:------:|:-----------:|:------:|:-----------:|:------:|:------------:|:------:|:------------:|:------:|:------------:|:------:|
| w/o MS‚ÄëTKD    | 79.8        | -2.0   | 54.4        | -5.1   | 54.2        | -5.6   | 7.5          | +0.9   | 8.3          | +1.1   | 7.8          | +1.0   |
| w/o GSME      | 78.3        | -3.5   | 55.1        | -4.4   | 53.4        | -6.4   | 9.6          | +3.0   | 9.7          | +2.5   | 9.5          | +2.7   |
| w/o SLKD      | 80.0        | -1.8   | 56.1        | -3.4   | 55.2        | -4.6   | 8.1          | +1.5   | 8.7          | +1.5   | 8.0          | +1.2   |
| **Ours**      | **81.8**    | -      | **59.5**    | -    | **59.8**    | -    | **6.6**      | -    | **7.2**      |  -    | **6.8**      |  -    |

---

### Ablation Study on FeTS‚ÄØ2024

Ablations on the *FeTS‚ÄØ2024* dataset paint a consistent picture: removing **MS‚ÄëTKD**, **GSME**, or **SLKD** lowered WT/TC/ET Dice from **88.2‚ÄØ% /‚ÄØ84.3‚ÄØ% /‚ÄØ73.4‚ÄØ%** to  

* **87.0‚ÄØ% /‚ÄØ81.8‚ÄØ% /‚ÄØ72.6‚ÄØ%** (‚àíMS‚ÄëTKD)  
* **86.1‚ÄØ% /‚ÄØ82.9‚ÄØ% /‚ÄØ72.6‚ÄØ%** (‚àíGSME)  
* **87.5‚ÄØ% /‚ÄØ82.1‚ÄØ% /‚ÄØ72.9‚ÄØ%** (‚àíSLKD)  

while **HD95** in all three regions fluctuated by **0.4‚ÄØ-‚ÄØ1.0‚ÄØmm**. Qualitatively, the absence of MS‚ÄëTKD blurred tumour contours, the lack of GSME distorted boundary textures, and skipping SLKD weakened ET detail.

Across all **15** missing‚Äëmodality combinations, the complete **MST‚ÄëKDNet** achieved an average **1.5‚ÄØ-‚ÄØ2.3‚ÄØpp** Dice gain and ‚âà‚ÄØ**1‚ÄØmm** HD95 reduction, validating the synergistic effect of multi‚Äëscale alignment, style compensation, and logit distillation.

| Method        | WT Dice (%) | Œî     | TC Dice (%) | Œî     | ET Dice (%) | Œî     | WT HD95 (mm) | Œî     | TC HD95 (mm) | Œî     | ET HD95 (mm) | Œî     |
|:-------------:|:-----------:|:-----:|:-----------:|:-----:|:-----------:|:-----:|:------------:|:-----:|:------------:|:-----:|:------------:|:-----:|
| w/o MS‚ÄëTKD    | 87.0        | -1.2  | 81.8        | -2.5  | 72.6        | -0.8  | 7.3          | +1.4  | 6.8          | +1.1  | 5.5          | +0.1  |
| w/o GSME      | 86.1        | -2.1  | 82.9        | -1.4  | 72.6        | -0.8  | 7.3          | +1.4  | 6.6          | +0.9  | 5.9          | +0.5  |
| w/o SLKD      | 87.5        | -0.7  | 82.1        | -2.2  | 72.9        | -0.5  | 6.5          | +0.6  | 6.6          | +0.9  | 5.8          | +0.4  |
| **Ours**      | **88.2**    |  -  | **84.3**    | -  | **73.4**    |  -  | **5.9**      |  -  | **5.7**      |  -  | **5.4**      |  -  |

## ü§ù Contributing

>üìã Pick a licence and describe how to contribute to your code repository. 

